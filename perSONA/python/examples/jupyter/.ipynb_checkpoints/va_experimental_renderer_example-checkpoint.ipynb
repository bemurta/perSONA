{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VA experimental renderer example\n",
    "VA has prototype renderers, that can be used for quick auralization of any given situation. A renderer of the **PrototypeGenericPath** class uses a uniform block convolution of required number of channels and filter length. For each source-listener-pair, a new convolution instance is provided. It can be updated using the parameter setter, i.e. the FIR filter can be updated in real-time with an impulse resonse (IR) in time domain directly out of Python (or Matlab). On server side, no files (except for the signal sources, if an audio file is used) have to be provided.\n",
    "\n",
    "The filter length, the number of channels and the number of source-listener-pairs are only limited by the computational power you can provide.\n",
    "\n",
    "This combination of a VA server with an experimental rendering module using the **PrototypeGenericPath** renderer can effectively be used for teaching purposes, i.e. to implement a real-time binaural auralization in Python or Matlab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected, server core version is: VACore v2017.d (debug)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#sys.path.append( '../../Lib/site-packages' )\n",
    "sys.path.append( '../../dist/Lib/site-packages' )\n",
    "import ipywidgets as widgets\n",
    "import va\n",
    "if not va.connect() :\n",
    "    raise 'Could not connect to local VA server'\n",
    "else :\n",
    "    print( 'Successfully connected, server core version is: ' + va.get_version() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auralize room acoustics with a measured binaural room impulse response (BRIR)\n",
    "### Configuration\n",
    "You have to start a VA server, that instatiates a **PrototypeGenericPath** renderer with **two channels** and a filter length that is long enough to fit the reverberation time of the room you want to make audible, for example **2 seconds** (or **88200 samples** at a sampling frequency of 44.1 kHz). If you start the experimental server provided with a VA binary package, this configuration is already in place. See also `conf/VACore.experimental.ini` for further details.\n",
    "### Rendering module name\n",
    "Check out the rendering module name to know which rendering module to call. Use `get_rendering_modules` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimental\n"
     ]
    }
   ],
   "source": [
    "for rmod in va.get_rendering_modules() :\n",
    "    if rmod['class'] == 'PrototypeGenericPath' :\n",
    "        print( rmod['id'] )\n",
    "rmod_name = 'Experimental' # alter this if you are using a different name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get renderer information\n",
    "To receive useful information, renderer usually return available configurations if `get_renderer_parameters` is called without arguments. Try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       " --- GenericPath renderer instance 'Experimental' ---\n",
       "\n",
       "[help]\n",
       "If the call module struct contains a key with the name 'help', this help text will be shown and the return struct will be returned with the key name 'help'.\n",
       "\n",
       "[info]\n",
       "If the call module struct contains a key with the name 'info', information on the static configuration of the renderer will be returned.\n",
       "\n",
       "[update]\n",
       "For every successful path update, the VA source and sound receiver ID has to be passed like this:\n",
       " receiver: <int>, the number of the sound receiver identifier\n",
       " source: <int>, the number of the source identifier\n",
       "\n",
       "Updating the path filter (impulse response in time domain) for a sound receiver and a source can be performed in two ways:\n",
       " a) using a path to a multi-channel WAV file:\n",
       "    Provide a key with the name 'filepath' and the path to the WAV file (absolute or containing the macro '$(VADataDir)' or relative to the executable) [priority given to 'filepath' if b) also applies]\n",
       " b) sending floating-point data for each channel\n",
       "    Provide a key for each channel with the generic name 'ch#', where the hash is substituted by the actual number of channel (starting at 1), and the value to this key will contain floating point data (or a sample buffer). The call parameter struct does not necessarily have to contain all channels, also single channels will be updated if key is given.\n",
       "\n",
       "Note: the existence of the key 'verbose' will print update information at server console and will provide the update info as an 'info' key in the returned struct.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmod_generic_info = va.get_rendering_module_parameters( rmod_name )\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "display( Markdown( rmod_generic_info[ 'help' ] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, now that we know we should use the `info` key, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filterdelaysamples': 0,\n",
       " 'irfilterlengthsamples': 88200,\n",
       " 'numchannels': 2,\n",
       " 'numpaths': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va.get_rendering_module_parameters( rmod_name, { 'info' : True } )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data preparation\n",
    "Let us quickly set up a virtual scene using input data from the Internet.\n",
    "Download for example anechoic recordings directly from [here](http://www.openairlib.net/sites/default/files/anechoic/data/judebrereton/modern-clarinet-bb/mono/cl-mod-bb-piece-32.wav) and a binaural impulse response from [here](http://www.openairlib.net/sites/default/files/auralization/data/audiolab/lady-chapel-st-albans-cathedral/stereo/stalbans_a_binaural.wav). Either add the download folder as search path, or put the files where VA can find it (e.g. in the `data` folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "va.add_search_path( '../../../VACore/data' )\n",
    "va.add_search_path( 'C:\\dev\\VA\\VACore\\data' )\n",
    "\n",
    "signal_source_id = va.create_signal_source_buffer_from_file( 'cl-mod-bb-piece-32.wav' )\n",
    "va.set_signal_source_buffer_playback_action_str( signal_source_id, 'play' )\n",
    "va.set_signal_source_buffer_looping( signal_source_id, True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the scene\n",
    "To update a source-listener-pair, a scene should be set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimental sound source id: 1\n",
      "Experimental listener id: 1\n"
     ]
    }
   ],
   "source": [
    "sound_source_id = va.create_sound_source( 'PyExperimentalSoundSource' )\n",
    "print( 'Experimental sound source id: ' + str( sound_source_id ) )\n",
    "va.set_sound_source_signal_source( sound_source_id, signal_source_id )\n",
    "receiver_id = va.create_sound_receiver( 'PyExperimentalListener' )\n",
    "print( 'Experimental listener id: ' + str( sound_source_id ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating paths\n",
    "Now that we have a source-listener-pair established, we can update the impulse response of that path. To do so, we have to assembly a `dict` variable that provides the required information. This `dict` will be transmitted to the renderer and the update will be performed.\n",
    "\n",
    "### Setting a simple unequal two-channel dirac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'receiver': 1, 'source': 1, 'ch1': [0.9, 0.0, 0.0, 0.0], 'ch2': [0.0, 0.0, -0.4, 0.0], 'verbose': True}\n"
     ]
    }
   ],
   "source": [
    "update_dirac = dict()\n",
    "update_dirac[ 'receiver' ] = receiver_id\n",
    "update_dirac[ 'source' ] = sound_source_id\n",
    "update_dirac[ 'ch1' ] = [ 0.9, 0.0,  0.0, 0.0 ] # Length of samples is arbitrary, here\n",
    "update_dirac[ 'ch2' ] = [ 0.0, 0.0, -0.4, 0.0 ] # Length of samples is arbitrary, here\n",
    "update_dirac[ 'verbose' ] = True; # Get information about update as a result\n",
    "print( update_dirac )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all we have to do is transmit the update task to the renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "va.set_rendering_module_parameters( rmod_name, update_dirac )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update by loading from a file path\n",
    "\n",
    "It is not necessary to transmit an entire impulse response for each channel to the path you want to update. You can also use a file path for a single or all channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'receiver': 1, 'source': 1, 'filepath': 'stalbans_a_binaural.wav', 'verbose': True}\n"
     ]
    }
   ],
   "source": [
    "update_filepath = dict()\n",
    "update_filepath[ 'receiver' ] = receiver_id\n",
    "update_filepath[ 'source' ] = sound_source_id\n",
    "update_filepath[ 'filepath' ] = 'stalbans_a_binaural.wav'\n",
    "#update_filepath[ 'channel' ] = 2 # ... in case you explicitly want to update a single channel with a mono IR file\n",
    "update_filepath[ 'verbose' ] = True;\n",
    "print( update_filepath )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "va.set_rendering_module_parameters( rmod_name, update_filepath )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update by loading samples into Python and transmit IR\n",
    "If you want to load an manipulate samples using Python, you can do the following. Make sure that the file is in the same folder of this notebook, or modify path accordingly.\n",
    "\n",
    "You can use `scipy` or `wave` to obtain data from a WAVE file, however sample type conversion might be an issue because they usually only provide integer type, and VA requires floating point samples. In this example, the input file is a 24bit signed integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded an impulse response of 2 channel(s) with 264600 filter taps.\n"
     ]
    }
   ],
   "source": [
    "import wave, struct\n",
    "w = wave.open( 'stalbans_a_binaural.wav' )\n",
    "raw_ir = w.readframes( w.getnframes() )\n",
    "ir_length = w.getnframes()\n",
    "ir_channels = w.getnchannels()\n",
    "assert( w.getsampwidth() == 3 )\n",
    "\n",
    "# Deinterleave and convert sample type (slow implementation, but more easy to interpret)\n",
    "ir = list()\n",
    "for n in range( ir_channels ) :\n",
    "    ir.append( [] )\n",
    "    for i in range( ir_length ) :\n",
    "        rbegin = 3 * ( n + i * ir_channels + 0 )\n",
    "        rend   = 3 * ( n + i * ir_channels + 1 )\n",
    "        sample_sint24 = raw_ir[ rbegin : rend ]\n",
    "        sample_sint32 = sample_sint24 + ( b'\\0' if sample_sint24[2] < 128 else b'\\xff' )\n",
    "        sample_float = ( struct.unpack( 'i', sample_sint32 )[0] ) / pow( 2, 24 - 1 )\n",
    "        ir[ n ].append( sample_float )\n",
    "\n",
    "print( 'Loaded an impulse response of %i channel(s) with %i filter taps.' % ( len( ir ), len( ir[ 0 ] ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_ir = dict()\n",
    "update_ir[ 'receiver' ] = receiver_id\n",
    "update_ir[ 'source' ] = sound_source_id\n",
    "update_ir[ 'ch1' ] = ir[ 0 ]; # Requires ir samples to be floating point, so sample type conversion might be required\n",
    "update_ir[ 'ch2' ] = ir[ 1 ]; # Requires ir samples to be floating point, so sample type conversion might be required\n",
    "update_ir[ 'verbose' ] = True;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "va.set_rendering_module_parameters( rmod_name, update_ir )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
